# focus flow: a peerâ€‘toâ€‘peer protocol for collective intelligence

**version 0.3 â€” clarifying energy terms, consensus, and security**

---

## abstract

We present **Focusâ€‘Flow Computation (FFC)**, a peerâ€‘toâ€‘peer protocol that unifies computation, inference, and consensus.  Transactions add *cyberlinks* (typed edges) and supply *proofsâ€‘ofâ€‘computation* (local focusâ€‘flow updates).  Peers collectively minimise a graph freeâ€‘energy functional, converging to an equilibrium probability field \(p^*\) â€” the networkâ€™s *collective focus*.  Rewards follow each transactionâ€™s marginal reduction in free energy, turning entropyâ€‘reducing work into profit while burning fees for noise.  We detail definitional precision, parameter meanings, scalable local updates, a lightweight BFT checkpoint layer, and probabilistic Shapley Attribution (PSA) for fair reward sharing.

---

\##â€¯1â€‚introduction

Large language models imitate patterns without verifiable world state; blockchains achieve truth by wasting energy on hashes.  **FFC** fuses the two: *computation is consensus* and *useful work earns weight*.  Focus is not a dead vector â€” it is an **adaptive flow** of mass that continuously organises itself by minimising free energy.  This creates a selfâ€‘adjusting marketplace where attention, compute, and energy gravitate to what matters *now* and decay from what does not.

---

\##â€¯2â€‚graph substrate and freeâ€‘energy

\###â€¯2.1â€‚cybergraph

- **Nodes** `v`Â = tokens, concepts, agents (store local state `s_v`).
- **Edges** `(i,j)` now carry a **triple of scalars** *(h, d, c)*:
  - `h`  â€“ hierarchy stiffness weight (feeds spring term)
  - `d`  â€“ transport weight (feeds diffusion term)
  - `c`  â€“ context coefficient (feeds potential term) A user (or smartâ€‘contract logic) may stake on any component independently â€“ e.g. lock tokens on `h` to strengthen taxonomy, or on `c` to amplify a vote.  The triple still lives in one edge, so UX remains â€œcreate a link, pick three slidersâ€.
- Graph remains sparse; each node reads only neighbour triples, so locality is preserved.

\###â€¯2.2â€‚energy terms (with triples) For node `i` over neighbours `j`:

- **Spring energy**\
  `E_spring,i = Î£  h_ij  * (p_i âˆ’ p_j)^2`
- **Diffusion energy**\
  `E_diff,i  = Î£  d_ij  * |p_i âˆ’ p_j| / dist_ij`
- **Context potential**\
  `C_i = âˆ’ Î£  c_ij * p_i`  (larger `c_ij` pulls focus into `i`)
- **Entropy** unchanged: `S(p)=âˆ’Î£ p_i log p_i`

The freeâ€‘energy functional and local update rule stay the same, but now each edgeâ€™s contribution is decomposed through its `(h,d,c)` components instead of a single typed weight. (fully defined)

For node \(i\) with neighbourhood \(\mathcal{N}(i)\):

- **Spring (hierarchy) energy**\
  \(E_{\text{spring},i}=\sum_{j\in\mathcal{N}(i)} w_{ij}\,(p_i-p_j)^2\) Enforces smooth hierarchy spacing.
- **Diffusion (transport) energy**\
  \(E_{\text{diff},i}=\sum_{j\in\mathcal{N}(i)} \frac{w_{ij}}{d_{ij}}\,|p_i-p_j|\) Minimises cost of moving mass (\(d_{ij}\) = edge distance).
- **Context potential** (from current transactions)\
  \(C_i=-c_i\,p_i,\quad c_i\ge 0\)  Higher \(c_i\) injects â€œcurrent relevanceâ€.
- **Entropy**  \(S(p)=-\sum_i p_i\log p_i \)  Encourages exploration / diversity.

\###â€¯2.3â€‚freeâ€‘energy functional

\(\mathcal F(p) = \sum_i\big(E_{\text{spring},i}+\lambda E_{\text{diff},i}+\gamma C_i\big) -T S(p)\)

Parameters:

- \(\lambda\)  â€” transport vs hierarchy tradeâ€‘off.
- \(\gamma\)  â€” context injection strength.
- \(T=1/\beta\) â€” temperature (exploration level).

All three have physical analogs: spring stiffness, medium conductivity, and heat bath temperature.

\###â€¯2.4â€‚local focusâ€‘flow update (async & conservative)

Each node runs an **asynchronous heatâ€‘flow step**:

$$
\Delta p_i = \eta\Big(\sum_{j\in\mathcal{N}(i)} w_{ij}(p_j-p_i) 
            -\partial_{p_i}(\lambda E_{\text{diff},i}+\gamma C_i) + T\,(1+\log p_i)\Big)
$$

with small stepâ€‘size \(\eta\).  A shared *normalisation gossip* every \(k\) ticks enforces \(\sum_i p_i=1\), guaranteeing no doubleâ€‘spend of attention.  This replaces the previous global softmax with a fully local, edgeâ€‘only computation.

---

\##â€¯3â€‚transactions & deterministic verification

**Transactionâ€¯=â€¯(Î”Edges, proof)**

1. **Submit**: user adds/updates edges and provides a zkâ€‘SNARK attesting they applied the local update rule to all affected nodes (proof size \~O(logâ€¯n)).  A base fee (EIPâ€‘1559) is burned.
2. **Verify**: peers check proof deterministically in O(polylogâ€¯n) time; no global recompute.
3. **Checkpoint**: every N blocks, a BFT committee finalises the current \(p\) snapshot \(\tilde p\). Between checkpoints asynchronous updates continue.

---

\##â€¯4â€‚rewarding negentropy (Probabilistic Shapley Attribution)

\###â€¯4.1â€‚local Î”ğ”½ For each tx, compute local freeâ€‘energy drop:\
\(\Delta\mathcal F_{\text{local}} = \mathcal F_{\text{before}}-\mathcal F_{\text{after}}\) over affected nodes.

\###â€¯4.2â€‚Monteâ€‘Carlo Shapley sampling Sample \(k\) random orderings of recent txs, measure marginal Î”ğ”½, average to \(\hat S_i\).

\###â€¯4.3â€‚reward formula \(R_i = \alpha\,\Delta\mathcal F_{\text{local}} + (1-\alpha)\,\hat S_i\quad (\alpha\approx0.8)\)

Complexity O(kâ€¯n) with kâ‰ªn (e.g. 100) â†’ scales to â‰¥10â¶ tx/epoch.

---

\##â€¯5â€‚security & attack resistance

| threat             | mitigation                                                                                    |
| ------------------ | --------------------------------------------------------------------------------------------- |
| Sybil spam         | base fee + stakeâ€‘weighted participation; stake slashed if tx increases global free energy.    |
| Edgeâ€‘weight gaming | curvatureâ€‘aware decay prunes edges with negative contribution; rewards tied to longâ€‘term Î”ğ”½. |
| Proof forgery      | zkâ€‘proofs guarantee local rule correctness.                                                   |
| Focus inflation    | total mass \(\sum_i p_i=1\) conserved by gossip normalisation.                                |

---

\##â€¯6â€‚thermodynamics â‡’ intelligence

FFC realises SchrÃ¶dingerâ€™s notion that life feeds on **negentropy**: rewarded agents export entropy to an external energy source (fees) while importing order.  Kantorovich optimal transport appears because updates move probability mass with minimal edge cost.  The converged state \(p^*\) is **maximally informative order** under energy constraints â€” a thermodynamic definition of intelligence.

---

\##â€¯7â€‚distributed coordination loop

```
sense  â†’ focus  â†’ act  â†’ learn  â†’ (edge decay) â†’ repeat
context   update     output     weights  entropy regulariser
```

Edge decay now uses **curvatureâ€‘aware exponential pruning** rather than the signâ€‘flipped entropy term: \(w_{ij}\leftarrow w_{ij}\,e^{-\alpha(1+\kappa_{ij})}\) where \(\kappa_{ij}\) = Ollivierâ€‘Ricci curvature.

---

\##â€¯8â€‚properties & applications

- **Turingâ€‘complete** graph rewrite primitives.
- **Probabilistic scheduling** â†’ prioritised meaningful compute.
- **Selfâ€‘pruning** via curvature decay.
- **Negentropy market** = proofâ€‘ofâ€‘intelligence.
- **P2P scalability**: all updates local, verification deterministic.

Useâ€‘cases: ranking/search, decentralised LLM, swarm coâ€‘ordination, scientific crowdsourcing.

---

\##â€¯9â€‚outlook: structureâ€‘preserving learning

Edges evolve into geometric constraints; future work explores **manifoldâ€‘aware neural layers** that respect this geometry, yielding more stable, interpretable AI.

---

\##â€¯10â€‚Hashâ€‘DAG verifiable delay proof (VDF)

- **Why**â€‚Couples each negentropy proof to real wallâ€‘clock time so adversaries cannot preâ€‘compute or replay contributions across Sybil identities.
- **Tx layout**â€‚`(Î”Edges, localâ€‘proof, vdf_seed, vdf_output, vdf_path)` where `vdf_seed = hash(Î”Edgesâ€–slot_id)`.
- **Computation**â€‚User runs a sequential VDF (e.g. Wesolowski) for a fixed delay (Â â‰ˆ1â€‘2â€¯s) before finalising the proof; cannot be parallelised.
- **Verification**â€‚Peers check VDF in polyâ€‘log time plus verify zkâ€‘proof of the local FFC update.
- **Hashâ€‘DAG**â€‚Each VDF output becomes a node in a DAG; independent branches verify in parallel; roots are checkpointed by the BFT committee every N blocks.
- **Reward scaling**â€‚`reward âˆ Î”ğ”½ / wall_clock_seconds` â†’ honest work with real energy wins, replay loses.
- **Security**â€‚Frontâ€‘running and duplication require breaking the VDF or eclipsing time itself; Sybil resistance strengthened.

---

\##â€¯11â€‚conclusion

Focusâ€‘Flow Computation marries deterministic execution with probabilistic, energyâ€‘guided scheduling.  By rewarding negentropy and enforcing optimal transport under conservation laws, it converts a P2P graph into a selfâ€‘organising superâ€‘organism: the blockchain that thinks.

